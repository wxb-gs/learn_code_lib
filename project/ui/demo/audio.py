import sys
import time
import threading
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.QtGui import *
import speech_recognition as sr
import pyaudio

class PulseEffect(QWidget):
    """è„‰å†²åŠ¨ç”»æ•ˆæœç»„ä»¶"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setFixedSize(200, 200)
        self.pulse_radius = 40
        self.max_radius = 80
        self.is_recording = False
        
        # åŠ¨ç”»å®šæ—¶å™¨
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_pulse)
        
    def start_pulse(self):
        self.is_recording = True
        self.timer.start(50)  # 50msé—´éš”
        
    def stop_pulse(self):
        self.is_recording = False
        self.timer.stop()
        self.pulse_radius = 40
        self.update()
        
    def update_pulse(self):
        if self.is_recording:
            self.pulse_radius += 2
            if self.pulse_radius > self.max_radius:
                self.pulse_radius = 40
            self.update()
    
    def paintEvent(self, event):
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        
        center = self.rect().center()
        
        if self.is_recording:
            # ç»˜åˆ¶è„‰å†²åœ†ç¯
            for i in range(3):
                alpha = max(0, 100 - i * 30 - (self.pulse_radius - 40) * 2)
                color = QColor(66, 165, 245, alpha)
                painter.setPen(QPen(color, 2))
                painter.setBrush(QBrush(color))
                radius = self.pulse_radius + i * 15
                painter.drawEllipse(center, radius, radius)
        
        # ç»˜åˆ¶ä¸­å¿ƒéº¦å…‹é£å›¾æ ‡
        icon_color = QColor(244, 67, 54) if self.is_recording else QColor(158, 158, 158)
        painter.setPen(QPen(icon_color, 3))
        painter.setBrush(QBrush(icon_color))
        
        # ç»˜åˆ¶éº¦å…‹é£å½¢çŠ¶
        mic_rect = QRect(center.x() - 15, center.y() - 20, 30, 35)
        painter.drawRoundedRect(mic_rect, 15, 15)
        
        # éº¦å…‹é£åº•åº§
        painter.drawLine(center.x(), center.y() + 20, center.x(), center.y() + 35)
        painter.drawLine(center.x() - 10, center.y() + 35, center.x() + 10, center.y() + 35)

class VoiceInputWidget(QWidget):
    """è¯­éŸ³è¾“å…¥ä¸»ç•Œé¢"""
    
    text_recognized = pyqtSignal(str)
    
    def __init__(self):
        super().__init__()
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.is_listening = False
        self.setup_ui()
        self.setup_speech_recognition()
        
    def setup_ui(self):
        self.setWindowTitle("ChatGPTé£æ ¼è¯­éŸ³è¾“å…¥")
        self.setFixedSize(600, 700)
        self.setStyleSheet("""
            QWidget {
                background-color: #1e1e1e;
                color: white;
                font-family: 'Segoe UI', Arial, sans-serif;
            }
            
            QPushButton {
                background-color: #2d2d2d;
                border: 2px solid #404040;
                border-radius: 12px;
                padding: 12px 24px;
                font-size: 14px;
                font-weight: bold;
            }
            
            QPushButton:hover {
                background-color: #404040;
                border-color: #4285f4;
            }
            
            QPushButton:pressed {
                background-color: #505050;
            }
            
            QPushButton#recordButton {
                background-color: #4285f4;
                border-color: #4285f4;
                color: white;
            }
            
            QPushButton#recordButton:hover {
                background-color: #3367d6;
            }
            
            QPushButton#recordButton:pressed {
                background-color: #2455c4;
            }
            
            QPushButton#stopButton {
                background-color: #ea4335;
                border-color: #ea4335;
                color: white;
            }
            
            QPushButton#stopButton:hover {
                background-color: #d33b2c;
            }
            
            QTextEdit {
                background-color: #2d2d2d;
                border: 2px solid #404040;
                border-radius: 12px;
                padding: 16px;
                font-size: 14px;
                line-height: 1.5;
            }
            
            QLabel {
                color: #e0e0e0;
                font-size: 16px;
            }
            
            QLabel#titleLabel {
                font-size: 24px;
                font-weight: bold;
                color: #4285f4;
            }
            
            QLabel#statusLabel {
                font-size: 14px;
                color: #9e9e9e;
            }
        """)
        
        layout = QVBoxLayout(self)
        layout.setSpacing(20)
        layout.setContentsMargins(40, 40, 40, 40)
        
        # æ ‡é¢˜
        title_label = QLabel("ğŸ¤ è¯­éŸ³è¾“å…¥åŠ©æ‰‹")
        title_label.setObjectName("titleLabel")
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # è„‰å†²åŠ¨ç”»åŒºåŸŸ
        pulse_container = QWidget()
        pulse_container.setFixedHeight(220)
        pulse_layout = QHBoxLayout(pulse_container)
        pulse_layout.setContentsMargins(0, 0, 0, 0)
        
        self.pulse_effect = PulseEffect()
        pulse_layout.addWidget(self.pulse_effect, alignment=Qt.AlignCenter)
        layout.addWidget(pulse_container)
        
        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("ç‚¹å‡»å¼€å§‹å½•éŸ³")
        self.status_label.setObjectName("statusLabel")
        self.status_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.status_label)
        
        # æŒ‰é’®åŒºåŸŸ
        button_layout = QHBoxLayout()
        button_layout.setSpacing(16)
        
        self.record_button = QPushButton("ğŸ™ï¸ å¼€å§‹å½•éŸ³")
        self.record_button.setObjectName("recordButton")
        self.record_button.clicked.connect(self.start_recording)
        
        self.stop_button = QPushButton("â¹ï¸ åœæ­¢å½•éŸ³")
        self.stop_button.setObjectName("stopButton")
        self.stop_button.clicked.connect(self.stop_recording)
        self.stop_button.setEnabled(False)
        
        self.clear_button = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºæ–‡æœ¬")
        self.clear_button.clicked.connect(self.clear_text)
        
        button_layout.addWidget(self.record_button)
        button_layout.addWidget(self.stop_button)
        button_layout.addWidget(self.clear_button)
        layout.addLayout(button_layout)
        
        # è¯†åˆ«ç»“æœæ˜¾ç¤º
        result_label = QLabel("è¯†åˆ«ç»“æœ:")
        layout.addWidget(result_label)
        
        self.result_text = QTextEdit()
        self.result_text.setPlaceholderText("è¯­éŸ³è¯†åˆ«çš„æ–‡æœ¬å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...")
        self.result_text.setMaximumHeight(200)
        layout.addWidget(self.result_text)
        
        # è¿æ¥ä¿¡å·
        self.text_recognized.connect(self.on_text_recognized)
        
    def setup_speech_recognition(self):
        """è®¾ç½®è¯­éŸ³è¯†åˆ«"""
        try:
            # è°ƒæ•´ç¯å¢ƒå™ªéŸ³
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
        except Exception as e:
            print(f"è®¾ç½®è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if not self.is_listening:
            self.is_listening = True
            self.record_button.setEnabled(False)
            self.stop_button.setEnabled(True)
            
            self.status_label.setText("ğŸ”´ æ­£åœ¨å½•éŸ³ï¼Œè¯·è¯´è¯...")
            self.pulse_effect.start_pulse()
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿›è¡Œè¯­éŸ³è¯†åˆ«
            threading.Thread(target=self.recognize_speech, daemon=True).start()
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        self.is_listening = False
        self.record_button.setEnabled(True)
        self.stop_button.setEnabled(False)
        
        self.status_label.setText("â¸ï¸ å½•éŸ³å·²åœæ­¢ï¼Œæ­£åœ¨å¤„ç†...")
        self.pulse_effect.stop_pulse()
    
    def recognize_speech(self):
        """è¯­éŸ³è¯†åˆ«çº¿ç¨‹"""
        try:
            with self.microphone as source:
                # ç›‘å¬éŸ³é¢‘
                audio_data = self.recognizer.listen(source, timeout=1, phrase_time_limit=10)
                
            if self.is_listening:
                # ä½¿ç”¨Googleè¯­éŸ³è¯†åˆ« (éœ€è¦ç½‘ç»œè¿æ¥)
                try:
                    text = self.recognizer.recognize_google(audio_data, language='zh-CN')
                    self.text_recognized.emit(text)
                except sr.UnknownValueError:
                    self.text_recognized.emit("[æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹]")
                except sr.RequestError as e:
                    self.text_recognized.emit(f"[è¯†åˆ«æœåŠ¡é”™è¯¯: {e}]")
                    
        except sr.WaitTimeoutError:
            if self.is_listening:
                # ç»§ç»­ç›‘å¬
                threading.Thread(target=self.recognize_speech, daemon=True).start()
        except Exception as e:
            self.text_recognized.emit(f"[å½•éŸ³é”™è¯¯: {e}]")
    
    def on_text_recognized(self, text):
        """å¤„ç†è¯†åˆ«åˆ°çš„æ–‡æœ¬"""
        current_text = self.result_text.toPlainText()
        if current_text:
            new_text = current_text + "\n" + text
        else:
            new_text = text
            
        self.result_text.setPlainText(new_text)
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.result_text.textCursor()
        cursor.movePosition(cursor.End)
        self.result_text.setTextCursor(cursor)
        
        if self.is_listening:
            self.status_label.setText("ğŸ”´ ç»§ç»­å½•éŸ³ä¸­...")
            # ç»§ç»­ç›‘å¬
            threading.Thread(target=self.recognize_speech, daemon=True).start()
        else:
            self.status_label.setText("âœ… è¯†åˆ«å®Œæˆ")
    
    def clear_text(self):
        """æ¸…ç©ºæ–‡æœ¬"""
        self.result_text.clear()
        self.status_label.setText("ğŸ“ æ–‡æœ¬å·²æ¸…ç©º")

class MainWindow(QMainWindow):
    """ä¸»çª—å£"""
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ChatGPTé£æ ¼è¯­éŸ³è¾“å…¥Demo")
        self.setWindowIcon(self.style().standardIcon(QStyle.SP_MediaVolume))
        
        # åˆ›å»ºä¸­å¿ƒéƒ¨ä»¶
        central_widget = VoiceInputWidget()
        self.setCentralWidget(central_widget)
        
        # çª—å£å±…ä¸­
        self.center_window()
        
    def center_window(self):
        """çª—å£å±…ä¸­æ˜¾ç¤º"""
        screen = QDesktopWidget().screenGeometry()
        size = self.geometry()
        self.move(
            (screen.width() - size.width()) // 2,
            (screen.height() - size.height()) // 2
        )

def main():
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨ç¨‹åºå±æ€§
    app.setApplicationName("è¯­éŸ³è¾“å…¥Demo")
    app.setApplicationVersion("1.0")
    
    # åˆ›å»ºå¹¶æ˜¾ç¤ºä¸»çª—å£
    window = MainWindow()
    window.show()
    
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()