from langgraph.types import StreamWriter
from langgraph.prebuilt import create_react_agent
from langchain_ollama import ChatOllama
import asyncio
from langgraph.config import get_stream_writer
# åˆå§‹åŒ– LLM å’Œå·¥å…·
llm = ChatOllama(model="qwen2.5:7b")

# è‡ªå®šä¹‰å·¥å…·èŠ‚ç‚¹ï¼ˆé›†æˆæµå¼è¾“å‡ºï¼‰


def get_weather_tool(city: str) -> str:
    """è·å–cityçš„å¤©æ°”

    Args:
        city (str): åŸå¸‚

    Returns:
        str: å¤©æ°”ç»“æœ
    """
    # writer = get_stream_writer()
    # writer.send("tool_progress", {"message": f"æŸ¥è¯¢{city}å¤©æ°”ä¸­..."})  # å‘é€è¿›åº¦äº‹ä»¶
    weather_data = "fetch_weather_api(city) "  # è°ƒç”¨çœŸå® API
    # writer.send("tool_result", {"data": weather_data})  # å‘é€ç»“æœäº‹ä»¶
    return weather_data


tools = [get_weather_tool]  # å‡è®¾å·²å®šä¹‰å¤©æ°”æŸ¥è¯¢å·¥å…·

# åˆ›å»º React Agent
agent = create_react_agent(llm, tools)


async def run_agent():
    inputs = {"messages": [{"role": "user", "content": "å¦‚ä½•å­¦ä¹ Rag?"}]}
    # agent.stream(input=inputs, stream_mode=["messages", "custom"])
    # ans = agent.invoke(inputs)
    # print(ans)

    async for event in agent.astream_events(
        inputs,
        version="v2"           # ä½¿ç”¨äº‹ä»¶æµ API
    ):
        event_type = event["event"]
        data = event["data"]
        # if event_type == "on_chat_model_stream":
        #     print(data)
        #     print("="*100)
        # print(event)

        # if event_type == "on_tool_start":
        #     print(f"ğŸ› ï¸ è°ƒç”¨å·¥å…·: {data['tool_name']}")

        # elif event_type == "tool_progress":  # å¤„ç†è‡ªå®šä¹‰å·¥å…·äº‹ä»¶
        #     print(f"â³ {data['message']}")

        # elif event_type == "tool_result":
        # #     print(f"âœ… æŸ¥è¯¢ç»“æœ: {data['data']}")

        # elif event_type == "on_chat_model_stream":  # LLM Token æµ
        #     print(data["chunk"].content, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(run_agent())
