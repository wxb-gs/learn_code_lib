# å®‰è£…ä¾èµ–
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from langchain_ollama import ChatOllama
from langchain_core.messages import AIMessage, ToolMessage  # æ–°å¢å¯¼å…¥
import asyncio
# å®Œæ•´ä»£ç 

# 1. åˆå§‹åŒ–æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹
model = ChatOllama(model="qwen2.5:7b")

# 2. å®šä¹‰å·¥å…·å‡½æ•°ï¼ˆå¸¦å®‰å…¨éªŒè¯ï¼‰


@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ï¼ˆä»…æ”¯æŒåŒ—äº¬/ä¸Šæµ·ï¼‰"""
    if city not in ["åŒ—äº¬", "ä¸Šæµ·"]:
        return "åŸå¸‚ä¸åœ¨æœåŠ¡èŒƒå›´"
    # æ¨¡æ‹ŸAPIè°ƒç”¨ï¼ˆå®é™…åº”æ›¿æ¢ä¸ºçœŸå®å¤©æ°”APIï¼‰
    weather_data = {"åŒ—äº¬": "æ™´ï¼Œ25â„ƒ", "ä¸Šæµ·": "å¤šäº‘ï¼Œ28â„ƒ"}
    return weather_data.get(city, "æ•°æ®æš‚ç¼º")


# 3. åˆ›å»ºå·¥å…·é›†åˆå¹¶å¯ç”¨çŠ¶æ€æŒä¹…åŒ–
tools = [get_weather]
checkpointer = MemorySaver()  # ä¿å­˜å¯¹è¯çŠ¶æ€

# 4. åˆ›å»ºReActæ™ºèƒ½ä»£ç†ï¼ˆå¸¦ä¸­æ–­æœºåˆ¶ï¼‰
agent = create_react_agent(
    model=model,
    tools=tools,
    checkpointer=checkpointer,
    prompt="""
don't need give the all (Thought/Action/Action Input/Observation), during the process you can give the part
Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can be repeated zero or more times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question"""
)


# def run_agent(query: str, thread_id: str = "test_thread"):
#     config = {"configurable": {"thread_id": thread_id}}
#     inputs = {"messages": [("user", query)]}

#     # æµå¼è¾“å‡ºæ‰§è¡Œè¿‡ç¨‹
#     print(f"ğŸ’¡ [Question]{query}")
#     for msg, meta in agent.stream(inputs, stream_mode="messages", config=config):
#         # è·å–å½“å‰æ­¥éª¤çš„æ¶ˆæ¯åˆ—è¡¨
#         msg.pretty_print()
#         print("="*100)

async def run():
    config = {"configurable": {"thread_id": "123"}}
    inputs = {"messages": [("user", "åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”åˆ†åˆ«å¦‚ä½•ï¼Ÿ")]}
    async for event in agent.astream_events(inputs, config):
        print(event)
        print("=="*50)

if __name__ == "__main__":
    # run_agent("åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”åˆ†åˆ«å¦‚ä½•ï¼Ÿ")
    asyncio.run(run())
